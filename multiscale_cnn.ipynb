{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Iman Wahle\n",
    "# Test multi-scale CNN \n",
    "# November 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/imanwahle/anaconda2/lib/python2.7/site-packages/cryptography/hazmat/primitives/constant_time.py:26: CryptographyDeprecationWarning: Support for your Python version is deprecated. The next version of cryptography will remove support. Please upgrade to a release (2.7.7+) that supports hmac.compare_digest as soon as possible.\n",
      "  utils.PersistentlyDeprecated2018,\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Dense, Flatten, MaxPooling2D, Dropout\n",
    "from keras.losses import sparse_categorical_crossentropy\n",
    "from keras.optimizers import SGD\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import TensorBoard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_data = np.load(\"X_data_fits.npy\")\n",
    "y_data = np.load(\"y_data_fits.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, 3, figsize=(18,4))\n",
    "\n",
    "y2d = y_data.copy()\n",
    "y2d[:,0] = y_data[:,0]//20\n",
    "idx = np.where(y2d[:,0]==5)[0]\n",
    "y2d[idx,0] = 4\n",
    "y2d[:,1] = y_data[:,1]//20\n",
    "y = y2d[:,1]*5 + y2d[:,0]\n",
    "\n",
    "# ax[0].plot(y_data[:,0],y2d[:,0],'.')\n",
    "# ax[0].set_xlabel('spin')\n",
    "# ax[0].set_ylabel('spin class')\n",
    "# ax[1].plot(y_data[:,1],y2d[:,1],'.')\n",
    "# ax[1].set_xlabel('incl')\n",
    "# ax[1].set_ylabel('incl class')\n",
    "# sns.scatterplot(y_data[:,0], y_data[:,1], hue=y, palette=\"jet\",ax=ax[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# format data\n",
    "\n",
    "# normalize the map to [0,1]\n",
    "maxmap_arr = np.max(X_data.reshape(X_data.shape[0],-1), axis = 1)\n",
    "Xnorm = np.tile(maxmap_arr, (X_data.shape[1], X_data.shape[2], 1))\n",
    "Xnorm = np.swapaxes(Xnorm, 0, 2)\n",
    "X = X_data/Xnorm\n",
    "\n",
    "X = X[..., np.newaxis]\n",
    "n_classes = len(np.unique(y))\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# one hot\n",
    "y_train = keras.utils.to_categorical(y_train, n_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # original single-scale model definition\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "#                  activation='relu',\n",
    "#                  input_shape=(100,100,1)))\n",
    "# model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(0.25))\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(128, activation='relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(n_classes, activation='softmax'))\n",
    "\n",
    "# model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_15 (Conv2D)           (None, 96, 96, 32)        832       \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 94, 94, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 47, 47, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 47, 47, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 141376)            0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 128)               18096256  \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 25)                3225      \n",
      "=================================================================\n",
      "Total params: 18,118,809\n",
      "Trainable params: 18,118,809\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 6817 samples, validate on 2273 samples\n",
      "Epoch 1/10\n",
      "6817/6817 [==============================] - 537s 79ms/step - loss: 1.5970 - acc: 0.4473 - mean_squared_error: 0.0271 - val_loss: 0.6055 - val_acc: 0.7659 - val_mean_squared_error: 0.0137\n",
      "Epoch 2/10\n",
      "6817/6817 [==============================] - 549s 81ms/step - loss: 0.8424 - acc: 0.6581 - mean_squared_error: 0.0179 - val_loss: 0.4454 - val_acc: 0.8258 - val_mean_squared_error: 0.0102\n",
      "Epoch 3/10\n",
      "6817/6817 [==============================] - 536s 79ms/step - loss: 0.6726 - acc: 0.7282 - mean_squared_error: 0.0148 - val_loss: 0.4111 - val_acc: 0.8311 - val_mean_squared_error: 0.0097\n",
      "Epoch 4/10\n",
      "6817/6817 [==============================] - 498s 73ms/step - loss: 0.5685 - acc: 0.7713 - mean_squared_error: 0.0127 - val_loss: 0.4075 - val_acc: 0.8311 - val_mean_squared_error: 0.0098\n",
      "Epoch 5/10\n",
      "6817/6817 [==============================] - 492s 72ms/step - loss: 0.5308 - acc: 0.7869 - mean_squared_error: 0.0120 - val_loss: 0.3376 - val_acc: 0.8636 - val_mean_squared_error: 0.0079\n",
      "Epoch 6/10\n",
      "6817/6817 [==============================] - 542s 79ms/step - loss: 0.4700 - acc: 0.8109 - mean_squared_error: 0.0106 - val_loss: 0.2608 - val_acc: 0.9094 - val_mean_squared_error: 0.0057\n",
      "Epoch 7/10\n",
      "6817/6817 [==============================] - 527s 77ms/step - loss: 0.4559 - acc: 0.8136 - mean_squared_error: 0.0104 - val_loss: 0.2781 - val_acc: 0.8795 - val_mean_squared_error: 0.0066\n",
      "Epoch 8/10\n",
      "6817/6817 [==============================] - 512s 75ms/step - loss: 0.4229 - acc: 0.8351 - mean_squared_error: 0.0095 - val_loss: 0.3182 - val_acc: 0.8544 - val_mean_squared_error: 0.0078\n",
      "Epoch 9/10\n",
      "6817/6817 [==============================] - 517s 76ms/step - loss: 0.4000 - acc: 0.8386 - mean_squared_error: 0.0092 - val_loss: 0.3277 - val_acc: 0.8566 - val_mean_squared_error: 0.0081\n",
      "Epoch 10/10\n",
      "6817/6817 [==============================] - 500s 73ms/step - loss: 0.3882 - acc: 0.8476 - mean_squared_error: 0.0088 - val_loss: 0.2893 - val_acc: 0.8843 - val_mean_squared_error: 0.0068\n",
      "('Test loss:', 0.28929439846555727)\n",
      "('Test accuracy:', 0.884293884733832)\n"
     ]
    }
   ],
   "source": [
    "# model 1 definition\n",
    "model_name = \"model1\"\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(5,5),\n",
    "                 activation='relu',\n",
    "                 input_shape=(100,100,1)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(n_classes, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# training\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy', 'mse'])\n",
    "\n",
    "# model.summary()\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test),\n",
    "          callbacks=[TensorBoard(log_dir='/tmp/multiscale/' + model_name)])\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "# Save the model\n",
    "model_yaml = model.to_yaml()\n",
    "with open('multiscale_' + model_name + '_weights.yaml', \"w\") as yaml_file:\n",
    "    yaml_file.write(model_yaml)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights('multiscale_' + model_name + '_weights.h5')\n",
    "yaml_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_17 (Conv2D)           (None, 96, 96, 32)        832       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 48, 48, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 46, 46, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 23, 23, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 23, 23, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 33856)             0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 128)               4333696   \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 25)                3225      \n",
      "=================================================================\n",
      "Total params: 4,356,249\n",
      "Trainable params: 4,356,249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 6817 samples, validate on 2273 samples\n",
      "Epoch 1/10\n",
      "6817/6817 [==============================] - 228s 33ms/step - loss: 1.7616 - acc: 0.3917 - mean_squared_error: 0.0293 - val_loss: 0.8594 - val_acc: 0.6155 - val_mean_squared_error: 0.0194\n",
      "Epoch 2/10\n",
      "6817/6817 [==============================] - 270s 40ms/step - loss: 0.9502 - acc: 0.6148 - mean_squared_error: 0.0200 - val_loss: 1.0515 - val_acc: 0.6027 - val_mean_squared_error: 0.0213\n",
      "Epoch 3/10\n",
      "6817/6817 [==============================] - 216s 32ms/step - loss: 0.7735 - acc: 0.6868 - mean_squared_error: 0.0168 - val_loss: 0.5248 - val_acc: 0.8077 - val_mean_squared_error: 0.0117\n",
      "Epoch 4/10\n",
      "6817/6817 [==============================] - 273s 40ms/step - loss: 0.6724 - acc: 0.7266 - mean_squared_error: 0.0150 - val_loss: 0.4845 - val_acc: 0.8192 - val_mean_squared_error: 0.0107\n",
      "Epoch 5/10\n",
      "6817/6817 [==============================] - 245s 36ms/step - loss: 0.6311 - acc: 0.7390 - mean_squared_error: 0.0142 - val_loss: 0.3777 - val_acc: 0.8394 - val_mean_squared_error: 0.0090\n",
      "Epoch 6/10\n",
      "6817/6817 [==============================] - 244s 36ms/step - loss: 0.5967 - acc: 0.7480 - mean_squared_error: 0.0136 - val_loss: 0.3226 - val_acc: 0.8803 - val_mean_squared_error: 0.0073\n",
      "Epoch 7/10\n",
      "6817/6817 [==============================] - 175s 26ms/step - loss: 0.5571 - acc: 0.7710 - mean_squared_error: 0.0126 - val_loss: 0.4616 - val_acc: 0.8183 - val_mean_squared_error: 0.0101\n",
      "Epoch 8/10\n",
      "6817/6817 [==============================] - 166s 24ms/step - loss: 0.5449 - acc: 0.7760 - mean_squared_error: 0.0123 - val_loss: 0.3477 - val_acc: 0.8399 - val_mean_squared_error: 0.0085\n",
      "Epoch 9/10\n",
      "6817/6817 [==============================] - 165s 24ms/step - loss: 0.5265 - acc: 0.7826 - mean_squared_error: 0.0119 - val_loss: 0.4690 - val_acc: 0.8055 - val_mean_squared_error: 0.0110\n",
      "Epoch 10/10\n",
      "6817/6817 [==============================] - 190s 28ms/step - loss: 0.4938 - acc: 0.7958 - mean_squared_error: 0.0113 - val_loss: 0.2736 - val_acc: 0.9006 - val_mean_squared_error: 0.0061\n",
      "('Test loss:', 0.2736039728621162)\n",
      "('Test accuracy:', 0.9005719313682358)\n"
     ]
    }
   ],
   "source": [
    "# model 2 definition\n",
    "model_name = \"model2\"\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(5,5),\n",
    "                 activation='relu',\n",
    "                 input_shape=(100,100,1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(n_classes, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# training\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy', 'mse'])\n",
    "\n",
    "# model.summary()\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test),\n",
    "          callbacks=[TensorBoard(log_dir='/tmp/multiscale/' + model_name)])\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "# Save the model\n",
    "model_yaml = model.to_yaml()\n",
    "with open('multiscale_' + model_name + '_weights.yaml', \"w\") as yaml_file:\n",
    "    yaml_file.write(model_yaml)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights('multiscale_' + model_name + '_weights.h5')\n",
    "yaml_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_19 (Conv2D)           (None, 94, 94, 32)        1600      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 47, 47, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 45, 45, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 22, 22, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 22, 22, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 30976)             0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 128)               3965056   \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 25)                3225      \n",
      "=================================================================\n",
      "Total params: 3,988,377\n",
      "Trainable params: 3,988,377\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 6817 samples, validate on 2273 samples\n",
      "Epoch 1/10\n",
      "6817/6817 [==============================] - 201s 29ms/step - loss: 1.7735 - acc: 0.3763 - mean_squared_error: 0.0296 - val_loss: 1.0755 - val_acc: 0.5684 - val_mean_squared_error: 0.0228\n",
      "Epoch 2/10\n",
      "6817/6817 [==============================] - 205s 30ms/step - loss: 0.9825 - acc: 0.6047 - mean_squared_error: 0.0205 - val_loss: 0.5148 - val_acc: 0.8091 - val_mean_squared_error: 0.0115\n",
      "Epoch 3/10\n",
      "6817/6817 [==============================] - 228s 33ms/step - loss: 0.7836 - acc: 0.6887 - mean_squared_error: 0.0170 - val_loss: 0.8353 - val_acc: 0.6709 - val_mean_squared_error: 0.0179\n",
      "Epoch 4/10\n",
      "6817/6817 [==============================] - 200s 29ms/step - loss: 0.7067 - acc: 0.7094 - mean_squared_error: 0.0154 - val_loss: 0.4081 - val_acc: 0.8575 - val_mean_squared_error: 0.0090\n",
      "Epoch 5/10\n",
      "6817/6817 [==============================] - 217s 32ms/step - loss: 0.6408 - acc: 0.7405 - mean_squared_error: 0.0142 - val_loss: 0.3370 - val_acc: 0.8755 - val_mean_squared_error: 0.0077\n",
      "Epoch 6/10\n",
      "6817/6817 [==============================] - 201s 29ms/step - loss: 0.5951 - acc: 0.7556 - mean_squared_error: 0.0134 - val_loss: 0.3660 - val_acc: 0.8465 - val_mean_squared_error: 0.0086\n",
      "Epoch 7/10\n",
      "6817/6817 [==============================] - 199s 29ms/step - loss: 0.5635 - acc: 0.7734 - mean_squared_error: 0.0126 - val_loss: 0.3403 - val_acc: 0.8737 - val_mean_squared_error: 0.0078\n",
      "Epoch 8/10\n",
      "6817/6817 [==============================] - 210s 31ms/step - loss: 0.5391 - acc: 0.7797 - mean_squared_error: 0.0121 - val_loss: 0.2907 - val_acc: 0.8944 - val_mean_squared_error: 0.0066\n",
      "Epoch 9/10\n",
      "6817/6817 [==============================] - 209s 31ms/step - loss: 0.5204 - acc: 0.7898 - mean_squared_error: 0.0118 - val_loss: 0.2955 - val_acc: 0.8649 - val_mean_squared_error: 0.0073\n",
      "Epoch 10/10\n",
      "6817/6817 [==============================] - 196s 29ms/step - loss: 0.5091 - acc: 0.7926 - mean_squared_error: 0.0114 - val_loss: 0.2576 - val_acc: 0.9182 - val_mean_squared_error: 0.0056\n",
      "('Test loss:', 0.25762459290904244)\n",
      "('Test accuracy:', 0.9181698196216455)\n"
     ]
    }
   ],
   "source": [
    "# model 3 definition\n",
    "model_name = \"model3\"\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(7,7),\n",
    "                 activation='relu',\n",
    "                 input_shape=(100,100,1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(n_classes, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# training\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy', 'mse'])\n",
    "\n",
    "# model.summary()\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test),\n",
    "          callbacks=[TensorBoard(log_dir='/tmp/multiscale/' + model_name)])\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "# Save the model\n",
    "model_yaml = model.to_yaml()\n",
    "with open('multiscale_' + model_name + '_weights.yaml', \"w\") as yaml_file:\n",
    "    yaml_file.write(model_yaml)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights('multiscale_' + model_name + '_weights.h5')\n",
    "yaml_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_13 (Conv2D)           (None, 96, 96, 32)        832       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 48, 48, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 46, 46, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 23, 23, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 23, 23, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 33856)             0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 128)               4333696   \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 25)                3225      \n",
      "=================================================================\n",
      "Total params: 4,356,249\n",
      "Trainable params: 4,356,249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 6817 samples, validate on 2273 samples\n",
      "Epoch 1/50\n",
      "6817/6817 [==============================] - 165s 24ms/step - loss: 1.6898 - acc: 0.4146 - mean_squared_error: 0.0283 - val_loss: 0.7913 - val_acc: 0.6639 - val_mean_squared_error: 0.0176\n",
      "Epoch 2/50\n",
      "6817/6817 [==============================] - 162s 24ms/step - loss: 0.8985 - acc: 0.6325 - mean_squared_error: 0.0193 - val_loss: 0.5301 - val_acc: 0.7831 - val_mean_squared_error: 0.0123\n",
      "Epoch 3/50\n",
      "6817/6817 [==============================] - 166s 24ms/step - loss: 0.7203 - acc: 0.7018 - mean_squared_error: 0.0161 - val_loss: 0.5237 - val_acc: 0.7418 - val_mean_squared_error: 0.0129\n",
      "Epoch 4/50\n",
      "6817/6817 [==============================] - 164s 24ms/step - loss: 0.6319 - acc: 0.7354 - mean_squared_error: 0.0143 - val_loss: 0.3906 - val_acc: 0.8319 - val_mean_squared_error: 0.0092\n",
      "Epoch 5/50\n",
      "6817/6817 [==============================] - 165s 24ms/step - loss: 0.5926 - acc: 0.7577 - mean_squared_error: 0.0134 - val_loss: 0.4744 - val_acc: 0.7954 - val_mean_squared_error: 0.0112\n",
      "Epoch 6/50\n",
      "6817/6817 [==============================] - 162s 24ms/step - loss: 0.5308 - acc: 0.7769 - mean_squared_error: 0.0122 - val_loss: 0.2809 - val_acc: 0.9037 - val_mean_squared_error: 0.0064\n",
      "Epoch 7/50\n",
      "6817/6817 [==============================] - 166s 24ms/step - loss: 0.5217 - acc: 0.7847 - mean_squared_error: 0.0119 - val_loss: 0.3956 - val_acc: 0.8209 - val_mean_squared_error: 0.0096\n",
      "Epoch 8/50\n",
      "6817/6817 [==============================] - 164s 24ms/step - loss: 0.4822 - acc: 0.8040 - mean_squared_error: 0.0109 - val_loss: 0.3677 - val_acc: 0.8399 - val_mean_squared_error: 0.0088\n",
      "Epoch 9/50\n",
      "6817/6817 [==============================] - 164s 24ms/step - loss: 0.4672 - acc: 0.8049 - mean_squared_error: 0.0106 - val_loss: 0.2696 - val_acc: 0.8922 - val_mean_squared_error: 0.0063\n",
      "Epoch 10/50\n",
      "6817/6817 [==============================] - 163s 24ms/step - loss: 0.4580 - acc: 0.8147 - mean_squared_error: 0.0105 - val_loss: 0.2994 - val_acc: 0.8825 - val_mean_squared_error: 0.0071\n",
      "Epoch 11/50\n",
      "6817/6817 [==============================] - 165s 24ms/step - loss: 0.4365 - acc: 0.8247 - mean_squared_error: 0.0099 - val_loss: 0.2738 - val_acc: 0.8834 - val_mean_squared_error: 0.0065\n",
      "Epoch 12/50\n",
      "6817/6817 [==============================] - 166s 24ms/step - loss: 0.4208 - acc: 0.8332 - mean_squared_error: 0.0096 - val_loss: 0.2353 - val_acc: 0.9111 - val_mean_squared_error: 0.0053\n",
      "Epoch 13/50\n",
      "6817/6817 [==============================] - 161s 24ms/step - loss: 0.4244 - acc: 0.8265 - mean_squared_error: 0.0098 - val_loss: 0.2017 - val_acc: 0.9314 - val_mean_squared_error: 0.0045\n",
      "Epoch 14/50\n",
      "6817/6817 [==============================] - 166s 24ms/step - loss: 0.4052 - acc: 0.8347 - mean_squared_error: 0.0093 - val_loss: 0.2440 - val_acc: 0.9006 - val_mean_squared_error: 0.0058\n",
      "Epoch 15/50\n",
      "6817/6817 [==============================] - 164s 24ms/step - loss: 0.3949 - acc: 0.8411 - mean_squared_error: 0.0090 - val_loss: 0.3277 - val_acc: 0.8742 - val_mean_squared_error: 0.0074\n",
      "Epoch 16/50\n",
      "6817/6817 [==============================] - 171s 25ms/step - loss: 0.3817 - acc: 0.8470 - mean_squared_error: 0.0088 - val_loss: 0.2290 - val_acc: 0.9116 - val_mean_squared_error: 0.0052\n",
      "Epoch 17/50\n",
      "6817/6817 [==============================] - 162s 24ms/step - loss: 0.3883 - acc: 0.8501 - mean_squared_error: 0.0088 - val_loss: 0.2213 - val_acc: 0.9059 - val_mean_squared_error: 0.0054\n",
      "Epoch 18/50\n",
      "6817/6817 [==============================] - 165s 24ms/step - loss: 0.3622 - acc: 0.8501 - mean_squared_error: 0.0083 - val_loss: 0.1645 - val_acc: 0.9344 - val_mean_squared_error: 0.0037\n",
      "Epoch 19/50\n",
      "6817/6817 [==============================] - 160s 24ms/step - loss: 0.3476 - acc: 0.8623 - mean_squared_error: 0.0079 - val_loss: 0.1730 - val_acc: 0.9331 - val_mean_squared_error: 0.0040\n",
      "Epoch 20/50\n",
      "6817/6817 [==============================] - 175s 26ms/step - loss: 0.3556 - acc: 0.8609 - mean_squared_error: 0.0081 - val_loss: 0.1845 - val_acc: 0.9270 - val_mean_squared_error: 0.0044\n",
      "Epoch 21/50\n",
      "6817/6817 [==============================] - 164s 24ms/step - loss: 0.3461 - acc: 0.8586 - mean_squared_error: 0.0080 - val_loss: 0.1842 - val_acc: 0.9327 - val_mean_squared_error: 0.0041\n",
      "Epoch 22/50\n",
      "6817/6817 [==============================] - 166s 24ms/step - loss: 0.3422 - acc: 0.8599 - mean_squared_error: 0.0079 - val_loss: 0.1629 - val_acc: 0.9393 - val_mean_squared_error: 0.0038\n",
      "Epoch 23/50\n",
      "6817/6817 [==============================] - 162s 24ms/step - loss: 0.3328 - acc: 0.8719 - mean_squared_error: 0.0075 - val_loss: 0.2507 - val_acc: 0.8957 - val_mean_squared_error: 0.0061\n",
      "Epoch 24/50\n",
      "6817/6817 [==============================] - 166s 24ms/step - loss: 0.3326 - acc: 0.8678 - mean_squared_error: 0.0076 - val_loss: 0.5958 - val_acc: 0.8223 - val_mean_squared_error: 0.0114\n",
      "Epoch 25/50\n",
      "6817/6817 [==============================] - 165s 24ms/step - loss: 0.3314 - acc: 0.8712 - mean_squared_error: 0.0075 - val_loss: 0.1634 - val_acc: 0.9287 - val_mean_squared_error: 0.0039\n",
      "Epoch 26/50\n",
      "6817/6817 [==============================] - 164s 24ms/step - loss: 0.3214 - acc: 0.8694 - mean_squared_error: 0.0074 - val_loss: 0.2489 - val_acc: 0.9045 - val_mean_squared_error: 0.0057\n",
      "Epoch 27/50\n",
      "6817/6817 [==============================] - 165s 24ms/step - loss: 0.3276 - acc: 0.8706 - mean_squared_error: 0.0075 - val_loss: 0.1562 - val_acc: 0.9375 - val_mean_squared_error: 0.0036\n",
      "Epoch 28/50\n",
      "6817/6817 [==============================] - 164s 24ms/step - loss: 0.3058 - acc: 0.8769 - mean_squared_error: 0.0070 - val_loss: 0.1444 - val_acc: 0.9481 - val_mean_squared_error: 0.0032\n",
      "Epoch 29/50\n",
      "6817/6817 [==============================] - 166s 24ms/step - loss: 0.3108 - acc: 0.8744 - mean_squared_error: 0.0072 - val_loss: 0.1784 - val_acc: 0.9239 - val_mean_squared_error: 0.0043\n",
      "Epoch 30/50\n",
      "6817/6817 [==============================] - 163s 24ms/step - loss: 0.3041 - acc: 0.8763 - mean_squared_error: 0.0071 - val_loss: 0.2896 - val_acc: 0.8940 - val_mean_squared_error: 0.0067\n",
      "Epoch 31/50\n",
      "6817/6817 [==============================] - 167s 24ms/step - loss: 0.2854 - acc: 0.8850 - mean_squared_error: 0.0066 - val_loss: 0.1324 - val_acc: 0.9428 - val_mean_squared_error: 0.0031\n",
      "Epoch 32/50\n",
      "6817/6817 [==============================] - 165s 24ms/step - loss: 0.3007 - acc: 0.8834 - mean_squared_error: 0.0069 - val_loss: 0.1301 - val_acc: 0.9520 - val_mean_squared_error: 0.0029\n",
      "Epoch 33/50\n",
      "6817/6817 [==============================] - 169s 25ms/step - loss: 0.2908 - acc: 0.8840 - mean_squared_error: 0.0067 - val_loss: 0.1265 - val_acc: 0.9512 - val_mean_squared_error: 0.0029\n",
      "Epoch 34/50\n",
      "6817/6817 [==============================] - 163s 24ms/step - loss: 0.2946 - acc: 0.8848 - mean_squared_error: 0.0067 - val_loss: 0.1351 - val_acc: 0.9454 - val_mean_squared_error: 0.0032\n",
      "Epoch 35/50\n",
      "6817/6817 [==============================] - 166s 24ms/step - loss: 0.2789 - acc: 0.8860 - mean_squared_error: 0.0064 - val_loss: 0.1266 - val_acc: 0.9463 - val_mean_squared_error: 0.0030\n",
      "Epoch 36/50\n",
      "6817/6817 [==============================] - 162s 24ms/step - loss: 0.2818 - acc: 0.8863 - mean_squared_error: 0.0066 - val_loss: 0.1455 - val_acc: 0.9410 - val_mean_squared_error: 0.0034\n",
      "Epoch 37/50\n",
      "6817/6817 [==============================] - 172s 25ms/step - loss: 0.2877 - acc: 0.8884 - mean_squared_error: 0.0065 - val_loss: 0.3007 - val_acc: 0.9006 - val_mean_squared_error: 0.0062\n",
      "Epoch 38/50\n",
      "6817/6817 [==============================] - 165s 24ms/step - loss: 0.2788 - acc: 0.8897 - mean_squared_error: 0.0064 - val_loss: 0.1138 - val_acc: 0.9578 - val_mean_squared_error: 0.0025\n",
      "Epoch 39/50\n",
      "6817/6817 [==============================] - 167s 24ms/step - loss: 0.2779 - acc: 0.8913 - mean_squared_error: 0.0064 - val_loss: 0.1310 - val_acc: 0.9459 - val_mean_squared_error: 0.0031\n",
      "Epoch 40/50\n",
      "6817/6817 [==============================] - 160s 24ms/step - loss: 0.2732 - acc: 0.8907 - mean_squared_error: 0.0064 - val_loss: 0.1254 - val_acc: 0.9547 - val_mean_squared_error: 0.0030\n",
      "Epoch 41/50\n",
      "6817/6817 [==============================] - 169s 25ms/step - loss: 0.2841 - acc: 0.8885 - mean_squared_error: 0.0066 - val_loss: 0.1512 - val_acc: 0.9331 - val_mean_squared_error: 0.0037\n",
      "Epoch 42/50\n",
      "6817/6817 [==============================] - 163s 24ms/step - loss: 0.2762 - acc: 0.8919 - mean_squared_error: 0.0064 - val_loss: 0.1109 - val_acc: 0.9639 - val_mean_squared_error: 0.0024\n",
      "Epoch 43/50\n",
      "6817/6817 [==============================] - 164s 24ms/step - loss: 0.2703 - acc: 0.8951 - mean_squared_error: 0.0062 - val_loss: 0.1402 - val_acc: 0.9454 - val_mean_squared_error: 0.0033\n",
      "Epoch 44/50\n",
      "6817/6817 [==============================] - 165s 24ms/step - loss: 0.2737 - acc: 0.8938 - mean_squared_error: 0.0062 - val_loss: 0.1097 - val_acc: 0.9604 - val_mean_squared_error: 0.0025\n",
      "Epoch 45/50\n",
      "6817/6817 [==============================] - 165s 24ms/step - loss: 0.2570 - acc: 0.8983 - mean_squared_error: 0.0059 - val_loss: 0.1163 - val_acc: 0.9534 - val_mean_squared_error: 0.0027\n",
      "Epoch 46/50\n",
      "6817/6817 [==============================] - 165s 24ms/step - loss: 0.2616 - acc: 0.8978 - mean_squared_error: 0.0060 - val_loss: 0.1008 - val_acc: 0.9608 - val_mean_squared_error: 0.0023\n",
      "Epoch 47/50\n",
      "6817/6817 [==============================] - 165s 24ms/step - loss: 0.2578 - acc: 0.8950 - mean_squared_error: 0.0059 - val_loss: 0.1149 - val_acc: 0.9520 - val_mean_squared_error: 0.0026\n",
      "Epoch 48/50\n",
      "6817/6817 [==============================] - 168s 25ms/step - loss: 0.2613 - acc: 0.8969 - mean_squared_error: 0.0060 - val_loss: 0.1473 - val_acc: 0.9428 - val_mean_squared_error: 0.0035\n",
      "Epoch 49/50\n",
      "6817/6817 [==============================] - 164s 24ms/step - loss: 0.2450 - acc: 0.9030 - mean_squared_error: 0.0056 - val_loss: 0.1014 - val_acc: 0.9666 - val_mean_squared_error: 0.0023\n",
      "Epoch 50/50\n",
      "6817/6817 [==============================] - 165s 24ms/step - loss: 0.2632 - acc: 0.9000 - mean_squared_error: 0.0060 - val_loss: 0.1200 - val_acc: 0.9503 - val_mean_squared_error: 0.0029\n",
      "('Test loss:', 0.11998113252966612)\n",
      "('Test accuracy:', 0.9502859656841179)\n"
     ]
    }
   ],
   "source": [
    "# model 4 definition\n",
    "model_name = \"model4\"\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(5,5),\n",
    "                 activation='relu',\n",
    "                 input_shape=(100,100,1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(n_classes, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# training\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy', 'mse'])\n",
    "\n",
    "# model.summary()\n",
    "batch_size = 32\n",
    "epochs = 50\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test),\n",
    "          callbacks=[TensorBoard(log_dir='/tmp/multiscale/' + model_name)])\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "# Save the model\n",
    "model_yaml = model.to_yaml()\n",
    "with open('multiscale_' + model_name + '_weights.yaml', \"w\") as yaml_file:\n",
    "    yaml_file.write(model_yaml)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights('multiscale_' + model_name + '_weights.h5')\n",
    "yaml_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 94, 94, 32)        1600      \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 90, 90, 64)        51264     \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 88, 88, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 44, 44, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 44, 44, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 123904)            0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               15859840  \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 25)                3225      \n",
      "=================================================================\n",
      "Total params: 15,952,857\n",
      "Trainable params: 15,952,857\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 6817 samples, validate on 2273 samples\n",
      "Epoch 1/10\n",
      "6817/6817 [==============================] - 1118s 164ms/step - loss: 1.7730 - acc: 0.4094 - mean_squared_error: 0.0286 - val_loss: 0.7595 - val_acc: 0.6934 - val_mean_squared_error: 0.0166\n",
      "Epoch 2/10\n",
      "6817/6817 [==============================] - 1084s 159ms/step - loss: 0.8806 - acc: 0.6591 - mean_squared_error: 0.0185 - val_loss: 0.8718 - val_acc: 0.6401 - val_mean_squared_error: 0.0190\n",
      "Epoch 3/10\n",
      "6817/6817 [==============================] - 1079s 158ms/step - loss: 0.6839 - acc: 0.7276 - mean_squared_error: 0.0147 - val_loss: 0.4837 - val_acc: 0.8016 - val_mean_squared_error: 0.0112\n",
      "Epoch 4/10\n",
      "6817/6817 [==============================] - 1078s 158ms/step - loss: 0.5569 - acc: 0.7794 - mean_squared_error: 0.0123 - val_loss: 0.4428 - val_acc: 0.8161 - val_mean_squared_error: 0.0101\n",
      "Epoch 5/10\n",
      "6817/6817 [==============================] - 1080s 158ms/step - loss: 0.5168 - acc: 0.7891 - mean_squared_error: 0.0115 - val_loss: 0.3165 - val_acc: 0.8702 - val_mean_squared_error: 0.0074\n",
      "Epoch 6/10\n",
      "6817/6817 [==============================] - 1076s 158ms/step - loss: 0.4669 - acc: 0.8134 - mean_squared_error: 0.0104 - val_loss: 0.2509 - val_acc: 0.9001 - val_mean_squared_error: 0.0059\n",
      "Epoch 7/10\n",
      "6817/6817 [==============================] - 1080s 158ms/step - loss: 0.4333 - acc: 0.8282 - mean_squared_error: 0.0097 - val_loss: 0.2011 - val_acc: 0.9195 - val_mean_squared_error: 0.0047\n",
      "Epoch 8/10\n",
      "6817/6817 [==============================] - 1077s 158ms/step - loss: 0.4028 - acc: 0.8414 - mean_squared_error: 0.0090 - val_loss: 0.1806 - val_acc: 0.9331 - val_mean_squared_error: 0.0042\n",
      "Epoch 9/10\n",
      "6817/6817 [==============================] - 1081s 159ms/step - loss: 0.3895 - acc: 0.8458 - mean_squared_error: 0.0088 - val_loss: 0.2140 - val_acc: 0.9098 - val_mean_squared_error: 0.0051\n",
      "Epoch 10/10\n",
      "6817/6817 [==============================] - 1078s 158ms/step - loss: 0.3594 - acc: 0.8535 - mean_squared_error: 0.0082 - val_loss: 0.3535 - val_acc: 0.8605 - val_mean_squared_error: 0.0079\n",
      "('Test loss:', 0.35352323375713257)\n",
      "('Test accuracy:', 0.8605367355917289)\n"
     ]
    }
   ],
   "source": [
    "# model 5 definition\n",
    "model_name = \"model5\"\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(7,7),\n",
    "                 activation='relu',\n",
    "                 input_shape=(100,100,1)))\n",
    "model.add(Conv2D(64, (5, 5), activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(n_classes, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# training\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy', 'mse'])\n",
    "\n",
    "# model.summary()\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test),\n",
    "          callbacks=[TensorBoard(log_dir='/tmp/multiscale/' + model_name)])\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "# Save the model\n",
    "model_yaml = model.to_yaml()\n",
    "with open('multiscale_' + model_name + '_weights.yaml', \"w\") as yaml_file:\n",
    "    yaml_file.write(model_yaml)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights('multiscale_' + model_name + '_weights.h5')\n",
    "yaml_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 98, 98, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 96, 96, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 48, 48, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 48, 48, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 147456)            0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               18874496  \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 25)                3225      \n",
      "=================================================================\n",
      "Total params: 18,896,537\n",
      "Trainable params: 18,896,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 6817 samples, validate on 2273 samples\n",
      "Epoch 1/100\n",
      "6817/6817 [==============================] - 368s 54ms/step - loss: 1.7475 - acc: 0.3999 - mean_squared_error: 0.0289 - val_loss: 0.9249 - val_acc: 0.6036 - val_mean_squared_error: 0.0200\n",
      "Epoch 2/100\n",
      "6817/6817 [==============================] - 368s 54ms/step - loss: 0.9631 - acc: 0.6233 - mean_squared_error: 0.0200 - val_loss: 0.7054 - val_acc: 0.7101 - val_mean_squared_error: 0.0158\n",
      "Epoch 3/100\n",
      "6817/6817 [==============================] - 368s 54ms/step - loss: 0.7719 - acc: 0.6959 - mean_squared_error: 0.0165 - val_loss: 0.6793 - val_acc: 0.6898 - val_mean_squared_error: 0.0161\n",
      "Epoch 4/100\n",
      "6817/6817 [==============================] - 368s 54ms/step - loss: 0.6622 - acc: 0.7371 - mean_squared_error: 0.0144 - val_loss: 0.4176 - val_acc: 0.8324 - val_mean_squared_error: 0.0097\n",
      "Epoch 5/100\n",
      "6817/6817 [==============================] - 371s 54ms/step - loss: 0.6242 - acc: 0.7487 - mean_squared_error: 0.0137 - val_loss: 0.3170 - val_acc: 0.8764 - val_mean_squared_error: 0.0073\n",
      "Epoch 6/100\n",
      "6817/6817 [==============================] - 368s 54ms/step - loss: 0.5740 - acc: 0.7720 - mean_squared_error: 0.0126 - val_loss: 0.5563 - val_acc: 0.7532 - val_mean_squared_error: 0.0131\n",
      "Epoch 7/100\n",
      "6817/6817 [==============================] - 376s 55ms/step - loss: 0.5466 - acc: 0.7805 - mean_squared_error: 0.0121 - val_loss: 0.2542 - val_acc: 0.9032 - val_mean_squared_error: 0.0058\n",
      "Epoch 8/100\n",
      "6817/6817 [==============================] - 368s 54ms/step - loss: 0.5187 - acc: 0.7886 - mean_squared_error: 0.0116 - val_loss: 0.2439 - val_acc: 0.9081 - val_mean_squared_error: 0.0055\n",
      "Epoch 9/100\n",
      "6817/6817 [==============================] - 368s 54ms/step - loss: 0.4800 - acc: 0.8048 - mean_squared_error: 0.0109 - val_loss: 0.2584 - val_acc: 0.8957 - val_mean_squared_error: 0.0061\n",
      "Epoch 10/100\n",
      "6817/6817 [==============================] - 368s 54ms/step - loss: 0.4631 - acc: 0.8184 - mean_squared_error: 0.0104 - val_loss: 0.2094 - val_acc: 0.9252 - val_mean_squared_error: 0.0047\n",
      "Epoch 11/100\n",
      "6817/6817 [==============================] - 369s 54ms/step - loss: 0.4462 - acc: 0.8250 - mean_squared_error: 0.0100 - val_loss: 0.2723 - val_acc: 0.9019 - val_mean_squared_error: 0.0061\n",
      "Epoch 12/100\n",
      "6817/6817 [==============================] - 369s 54ms/step - loss: 0.4150 - acc: 0.8312 - mean_squared_error: 0.0094 - val_loss: 0.1942 - val_acc: 0.9358 - val_mean_squared_error: 0.0043\n",
      "Epoch 13/100\n",
      "6817/6817 [==============================] - 368s 54ms/step - loss: 0.4208 - acc: 0.8325 - mean_squared_error: 0.0096 - val_loss: 0.1945 - val_acc: 0.9239 - val_mean_squared_error: 0.0044\n",
      "Epoch 14/100\n",
      "6817/6817 [==============================] - 367s 54ms/step - loss: 0.4091 - acc: 0.8373 - mean_squared_error: 0.0092 - val_loss: 0.1824 - val_acc: 0.9344 - val_mean_squared_error: 0.0040\n",
      "Epoch 15/100\n",
      "6817/6817 [==============================] - 371s 54ms/step - loss: 0.3992 - acc: 0.8356 - mean_squared_error: 0.0092 - val_loss: 0.1677 - val_acc: 0.9366 - val_mean_squared_error: 0.0038\n",
      "Epoch 16/100\n",
      "6817/6817 [==============================] - 368s 54ms/step - loss: 0.3789 - acc: 0.8474 - mean_squared_error: 0.0086 - val_loss: 0.1816 - val_acc: 0.9384 - val_mean_squared_error: 0.0040\n",
      "Epoch 17/100\n",
      "6817/6817 [==============================] - 368s 54ms/step - loss: 0.3688 - acc: 0.8518 - mean_squared_error: 0.0084 - val_loss: 0.3394 - val_acc: 0.8447 - val_mean_squared_error: 0.0083\n",
      "Epoch 18/100\n",
      "6817/6817 [==============================] - 370s 54ms/step - loss: 0.3649 - acc: 0.8529 - mean_squared_error: 0.0083 - val_loss: 0.1888 - val_acc: 0.9199 - val_mean_squared_error: 0.0046\n",
      "Epoch 19/100\n",
      "6817/6817 [==============================] - 374s 55ms/step - loss: 0.3515 - acc: 0.8571 - mean_squared_error: 0.0080 - val_loss: 0.2050 - val_acc: 0.9111 - val_mean_squared_error: 0.0050\n",
      "Epoch 20/100\n",
      "6817/6817 [==============================] - 371s 54ms/step - loss: 0.3587 - acc: 0.8536 - mean_squared_error: 0.0082 - val_loss: 0.2172 - val_acc: 0.9063 - val_mean_squared_error: 0.0053\n",
      "Epoch 21/100\n",
      "6817/6817 [==============================] - 370s 54ms/step - loss: 0.3599 - acc: 0.8593 - mean_squared_error: 0.0081 - val_loss: 0.1401 - val_acc: 0.9481 - val_mean_squared_error: 0.0032\n",
      "Epoch 22/100\n",
      "6817/6817 [==============================] - 369s 54ms/step - loss: 0.3363 - acc: 0.8637 - mean_squared_error: 0.0076 - val_loss: 0.1805 - val_acc: 0.9190 - val_mean_squared_error: 0.0045\n",
      "Epoch 23/100\n",
      "6817/6817 [==============================] - 368s 54ms/step - loss: 0.3338 - acc: 0.8650 - mean_squared_error: 0.0076 - val_loss: 0.3343 - val_acc: 0.8425 - val_mean_squared_error: 0.0082\n",
      "Epoch 24/100\n",
      "6817/6817 [==============================] - 368s 54ms/step - loss: 0.3210 - acc: 0.8721 - mean_squared_error: 0.0072 - val_loss: 0.1578 - val_acc: 0.9248 - val_mean_squared_error: 0.0039\n",
      "Epoch 25/100\n",
      "6817/6817 [==============================] - 368s 54ms/step - loss: 0.3194 - acc: 0.8760 - mean_squared_error: 0.0072 - val_loss: 0.1545 - val_acc: 0.9362 - val_mean_squared_error: 0.0037\n",
      "Epoch 26/100\n",
      "6817/6817 [==============================] - 371s 54ms/step - loss: 0.3140 - acc: 0.8790 - mean_squared_error: 0.0071 - val_loss: 0.1339 - val_acc: 0.9432 - val_mean_squared_error: 0.0031\n",
      "Epoch 27/100\n",
      "6817/6817 [==============================] - 368s 54ms/step - loss: 0.3053 - acc: 0.8807 - mean_squared_error: 0.0069 - val_loss: 0.1498 - val_acc: 0.9432 - val_mean_squared_error: 0.0035\n",
      "Epoch 28/100\n",
      "6817/6817 [==============================] - 369s 54ms/step - loss: 0.3053 - acc: 0.8784 - mean_squared_error: 0.0070 - val_loss: 0.1676 - val_acc: 0.9283 - val_mean_squared_error: 0.0040\n",
      "Epoch 29/100\n",
      "6817/6817 [==============================] - 369s 54ms/step - loss: 0.3090 - acc: 0.8750 - mean_squared_error: 0.0071 - val_loss: 0.1696 - val_acc: 0.9226 - val_mean_squared_error: 0.0042\n",
      "Epoch 30/100\n",
      "6817/6817 [==============================] - 368s 54ms/step - loss: 0.2994 - acc: 0.8771 - mean_squared_error: 0.0069 - val_loss: 0.1142 - val_acc: 0.9591 - val_mean_squared_error: 0.0025\n",
      "Epoch 31/100\n",
      "6817/6817 [==============================] - 369s 54ms/step - loss: 0.2965 - acc: 0.8838 - mean_squared_error: 0.0068 - val_loss: 0.1515 - val_acc: 0.9428 - val_mean_squared_error: 0.0035\n",
      "Epoch 32/100\n",
      "6817/6817 [==============================] - 367s 54ms/step - loss: 0.3137 - acc: 0.8731 - mean_squared_error: 0.0072 - val_loss: 0.1377 - val_acc: 0.9406 - val_mean_squared_error: 0.0032\n",
      "Epoch 33/100\n",
      "6817/6817 [==============================] - 368s 54ms/step - loss: 0.2978 - acc: 0.8782 - mean_squared_error: 0.0069 - val_loss: 0.1207 - val_acc: 0.9542 - val_mean_squared_error: 0.0028\n",
      "Epoch 34/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6817/6817 [==============================] - 369s 54ms/step - loss: 0.2849 - acc: 0.8866 - mean_squared_error: 0.0066 - val_loss: 0.2533 - val_acc: 0.9054 - val_mean_squared_error: 0.0056\n",
      "Epoch 35/100\n",
      "6817/6817 [==============================] - 369s 54ms/step - loss: 0.2887 - acc: 0.8837 - mean_squared_error: 0.0066 - val_loss: 0.1263 - val_acc: 0.9490 - val_mean_squared_error: 0.0030\n",
      "Epoch 36/100\n",
      "6817/6817 [==============================] - 370s 54ms/step - loss: 0.2760 - acc: 0.8873 - mean_squared_error: 0.0064 - val_loss: 0.3486 - val_acc: 0.8869 - val_mean_squared_error: 0.0072\n",
      "Epoch 37/100\n",
      "6817/6817 [==============================] - 369s 54ms/step - loss: 0.2845 - acc: 0.8895 - mean_squared_error: 0.0065 - val_loss: 0.1568 - val_acc: 0.9327 - val_mean_squared_error: 0.0038\n",
      "Epoch 38/100\n",
      "6817/6817 [==============================] - 371s 54ms/step - loss: 0.2774 - acc: 0.8884 - mean_squared_error: 0.0065 - val_loss: 0.1112 - val_acc: 0.9538 - val_mean_squared_error: 0.0026\n",
      "Epoch 39/100\n",
      "6817/6817 [==============================] - 369s 54ms/step - loss: 0.2766 - acc: 0.8919 - mean_squared_error: 0.0063 - val_loss: 0.1485 - val_acc: 0.9327 - val_mean_squared_error: 0.0037\n",
      "Epoch 40/100\n",
      "6817/6817 [==============================] - 396s 58ms/step - loss: 0.2639 - acc: 0.8951 - mean_squared_error: 0.0060 - val_loss: 0.1255 - val_acc: 0.9525 - val_mean_squared_error: 0.0029\n",
      "Epoch 41/100\n",
      "6817/6817 [==============================] - 379s 56ms/step - loss: 0.2798 - acc: 0.8887 - mean_squared_error: 0.0064 - val_loss: 0.1659 - val_acc: 0.9278 - val_mean_squared_error: 0.0040\n",
      "Epoch 42/100\n",
      "6817/6817 [==============================] - 423s 62ms/step - loss: 0.2687 - acc: 0.8941 - mean_squared_error: 0.0061 - val_loss: 0.2653 - val_acc: 0.8988 - val_mean_squared_error: 0.0060\n",
      "Epoch 43/100\n",
      "6817/6817 [==============================] - 642s 94ms/step - loss: 0.2780 - acc: 0.8875 - mean_squared_error: 0.0064 - val_loss: 0.1361 - val_acc: 0.9402 - val_mean_squared_error: 0.0033\n",
      "Epoch 44/100\n",
      "6817/6817 [==============================] - 644s 94ms/step - loss: 0.2667 - acc: 0.8931 - mean_squared_error: 0.0061 - val_loss: 0.3087 - val_acc: 0.8781 - val_mean_squared_error: 0.0071\n",
      "Epoch 45/100\n",
      "6817/6817 [==============================] - 575s 84ms/step - loss: 0.2642 - acc: 0.8969 - mean_squared_error: 0.0060 - val_loss: 0.1078 - val_acc: 0.9600 - val_mean_squared_error: 0.0024\n",
      "Epoch 46/100\n",
      "6817/6817 [==============================] - 369s 54ms/step - loss: 0.2541 - acc: 0.9008 - mean_squared_error: 0.0057 - val_loss: 0.1801 - val_acc: 0.9221 - val_mean_squared_error: 0.0044\n",
      "Epoch 47/100\n",
      "6817/6817 [==============================] - 380s 56ms/step - loss: 0.2572 - acc: 0.8956 - mean_squared_error: 0.0060 - val_loss: 0.1064 - val_acc: 0.9600 - val_mean_squared_error: 0.0025\n",
      "Epoch 48/100\n",
      "6817/6817 [==============================] - 367s 54ms/step - loss: 0.2571 - acc: 0.8992 - mean_squared_error: 0.0058 - val_loss: 0.1254 - val_acc: 0.9459 - val_mean_squared_error: 0.0031\n",
      "Epoch 49/100\n",
      "6817/6817 [==============================] - 366s 54ms/step - loss: 0.2560 - acc: 0.8994 - mean_squared_error: 0.0059 - val_loss: 0.1505 - val_acc: 0.9415 - val_mean_squared_error: 0.0035\n",
      "Epoch 50/100\n",
      "6817/6817 [==============================] - 398s 58ms/step - loss: 0.2598 - acc: 0.8972 - mean_squared_error: 0.0059 - val_loss: 0.1157 - val_acc: 0.9538 - val_mean_squared_error: 0.0027\n",
      "Epoch 51/100\n",
      "6817/6817 [==============================] - 434s 64ms/step - loss: 0.2535 - acc: 0.8991 - mean_squared_error: 0.0058 - val_loss: 0.2392 - val_acc: 0.8988 - val_mean_squared_error: 0.0058\n",
      "Epoch 52/100\n",
      "6817/6817 [==============================] - 429s 63ms/step - loss: 0.2567 - acc: 0.9022 - mean_squared_error: 0.0058 - val_loss: 0.1668 - val_acc: 0.9340 - val_mean_squared_error: 0.0039\n",
      "Epoch 53/100\n",
      "6817/6817 [==============================] - 495s 73ms/step - loss: 0.2552 - acc: 0.8976 - mean_squared_error: 0.0058 - val_loss: 0.1078 - val_acc: 0.9591 - val_mean_squared_error: 0.0025\n",
      "Epoch 54/100\n",
      "6817/6817 [==============================] - 654s 96ms/step - loss: 0.2486 - acc: 0.9038 - mean_squared_error: 0.0056 - val_loss: 0.1208 - val_acc: 0.9424 - val_mean_squared_error: 0.0030\n",
      "Epoch 55/100\n",
      "6817/6817 [==============================] - 461s 68ms/step - loss: 0.2488 - acc: 0.9039 - mean_squared_error: 0.0057 - val_loss: 0.1506 - val_acc: 0.9384 - val_mean_squared_error: 0.0037\n",
      "Epoch 56/100\n",
      "1440/6817 [=====>........................] - ETA: 5:06 - loss: 0.2353 - acc: 0.9118 - mean_squared_error: 0.0054"
     ]
    }
   ],
   "source": [
    "# model 6 definition\n",
    "model_name = \"model6\"\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3,3),\n",
    "                 activation='relu',\n",
    "                 input_shape=(100,100,1)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(n_classes, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# training\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy', 'mse'])\n",
    "\n",
    "# model.summary()\n",
    "batch_size = 32\n",
    "epochs = 100\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test),\n",
    "          callbacks=[TensorBoard(log_dir='/tmp/multiscale/' + model_name)])\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "# Save the model\n",
    "model_yaml = model.to_yaml()\n",
    "with open('multiscale_' + model_name + '_weights.yaml', \"w\") as yaml_file:\n",
    "    yaml_file.write(model_yaml)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights('multiscale_' + model_name + '_weights.h5')\n",
    "yaml_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model 7 definition\n",
    "model_name = \"model7\"\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(5,5),\n",
    "                 activation='relu',\n",
    "                 input_shape=(100,100,1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(n_classes, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# training\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy', 'mse'])\n",
    "\n",
    "# model.summary()\n",
    "batch_size = 32\n",
    "epochs = 100\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test),\n",
    "          callbacks=[TensorBoard(log_dir='/tmp/multiscale/' + model_name)])\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "# Save the model\n",
    "model_yaml = model.to_yaml()\n",
    "with open('multiscale_' + model_name + '_weights.yaml', \"w\") as yaml_file:\n",
    "    yaml_file.write(model_yaml)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights('multiscale_' + model_name + '_weights.h5')\n",
    "yaml_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
